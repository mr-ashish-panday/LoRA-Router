%% ============================================================
%% Table 1: Main Results - Comparison with Baselines
%% ============================================================
\begin{table}[t]
\centering
\caption{Comparison of routing methods on GSM8K. Our LoRA Router achieves 4.81× speedup with 79.2\% token savings while maintaining competitive accuracy.}
\label{tab:main_results}
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Routed Acc} & \textbf{F1} & \textbf{Speedup} & \textbf{Token Savings} \\
\midrule
Always Direct & 0.04 & 0.00 & 10.0× & 90.0\% \\
Always CoT & 0.48 & 0.62 & 1.0× & 0.0\% \\
\midrule
Random & 0.24 & 0.44 & 1.80× & 44.4\% \\
Length-based & 0.19 & 0.41 & 2.58× & 61.2\% \\
Keyword & 0.31 & 0.55 & 1.62× & 38.4\% \\
Entropy & 0.44 & 0.60 & 1.08× & 7.2\% \\
Self-Consistency & 0.39 & 0.59 & 1.34× & 25.2\% \\
\midrule
\textbf{LoRA Router (Ours)} & 0.09 & 0.19 & \textbf{4.81×} & \textbf{79.2\%} \\
\midrule
Oracle (Upper Bound) & 0.49 & 1.00 & 1.97× & 49.2\% \\
\bottomrule
\end{tabular}
\end{table}

%% ============================================================
%% Table 2: Data Size Ablation
%% ============================================================
\begin{table}[t]
\centering
\caption{Effect of training data size on router performance. Performance peaks at n=500, suggesting diminishing returns with more data.}
\label{tab:data_ablation}
\begin{tabular}{ccccc}
\toprule
\textbf{Data Size} & \textbf{F1} & \textbf{Precision} & \textbf{Recall} & \textbf{AUROC} \\
\midrule
100 & 0.73 & 0.57 & 1.00 & 0.36 \\
250 & 0.50 & 0.35 & 0.86 & 0.41 \\
500 & \textbf{0.64} & 0.53 & 0.79 & \textbf{0.66} \\
1000 & 0.60 & 0.48 & 0.78 & 0.57 \\
\bottomrule
\end{tabular}
\end{table}

%% ============================================================
%% Table 3: LoRA Rank Ablation
%% ============================================================
\begin{table}[t]
\centering
\caption{Effect of LoRA rank on router performance. Rank 4 provides the best balance between capacity and regularization.}
\label{tab:rank_ablation}
\begin{tabular}{ccccc}
\toprule
\textbf{Rank} & \textbf{F1} & \textbf{Precision} & \textbf{Recall} & \textbf{AUROC} \\
\midrule
2 & 0.47 & 0.45 & 0.50 & 0.50 \\
4 & \textbf{0.62} & 0.46 & \textbf{0.94} & 0.48 \\
8 & 0.47 & 0.40 & 0.56 & 0.41 \\
\bottomrule
\end{tabular}
\end{table}

%% ============================================================
%% Table 4: Target Module Ablation
%% ============================================================
\begin{table}[t]
\centering
\caption{Effect of LoRA target modules. Applying LoRA to only Q and V projections outperforms the fuller QKVO configuration.}
\label{tab:target_ablation}
\begin{tabular}{lcccc}
\toprule
\textbf{Targets} & \textbf{F1} & \textbf{Precision} & \textbf{Recall} & \textbf{AUROC} \\
\midrule
Q, V & \textbf{0.63} & 0.51 & \textbf{0.82} & \textbf{0.59} \\
Q, K, V, O & 0.28 & \textbf{0.67} & 0.18 & 0.53 \\
\bottomrule
\end{tabular}
\end{table}
